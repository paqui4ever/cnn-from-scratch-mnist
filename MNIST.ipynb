{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zt3DLH7yI7Fv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch_directml\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we must define the device to work on, this time we will be using DirectML because training will be done on an AMD RX 5700XT "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T2WI3qoU4gut"
      },
      "outputs": [],
      "source": [
        "device = torch_directml.device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we must download the datasets, both for testing and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeKVv7riKF7T",
        "outputId": "2a1ef9b4-ccb4-4e14-f48f-334bad9b2734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:07<00:00, 1269182.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 191292.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1396808.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ds = torchvision.datasets.MNIST(root = \"./data\", download = True, train = True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QSRwFtaMQmrK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\srene\\AppData\\Local\\Temp\\ipykernel_18248\\3138855485.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
            "  x_total = torch.tensor(list(map(lambda z: np.array(z[0]), ds)), dtype=torch.float32).to(device) # Converting to tensor of tensors the list of first elements of the ds tuples\n"
          ]
        }
      ],
      "source": [
        "x_total = torch.tensor(list(map(lambda z: np.array(z[0]), ds)), dtype=torch.float32).to(device) # Converting to tensor of tensors the list of first elements of the ds tuples \n",
        "y_total = (torch.nn.functional.one_hot(torch.tensor(list(map(lambda z: z[1], ds))), num_classes=10)).to(torch.float32).to(device) # Converting all labels to one hot encoding to see which number from 0 to 9 are they representing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jwbEHhHQmoe",
        "outputId": "397edc79-257a-4841-fdfa-26433e5efa34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([60000, 10]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_total.shape, y_total.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrWkXUA76CSk"
      },
      "source": [
        "Divido el dataset original en training y testing, creo sus loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cbtHE1k7Qmb6"
      },
      "outputs": [],
      "source": [
        "x_train = x_total[:50000].view(-1,1,28,28)\n",
        "y_train = y_total[:50000]\n",
        "x_test = x_total[50000:].view(-1,1,28,28)\n",
        "y_test = y_total[50000:]\n",
        "\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader (dataset = train_dataset, batch_size = 32, shuffle = True)\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader (dataset = test_dataset, batch_size = 32, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjMtNKnrV0S6"
      },
      "source": [
        "Creo el modelo\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E2hAYHWGV3Ci"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    # First convolutional layer\n",
        "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    # second convolutional layer\n",
        "    nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    # Flattening both convolutional layers\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 14 * 14, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128,10)\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDdl6Vpr62Wb"
      },
      "source": [
        "Entreno el modelo con un loop de entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "Jos5UXlyOlkx",
        "outputId": "7aa448ea-c15d-44bc-ff80-5b58495e04ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 412.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 418.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.44000000000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 418.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 409.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 434.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 427.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 415.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 406.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 393.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.46000000000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:03<00:00, 407.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.44000000000001\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for inputs, targets in tqdm(train_loader):\n",
        "      inputs, targets = inputs.to(device).float(), targets.to(device).float() \n",
        "      optimizer.zero_grad()  # Reseting the gradient\n",
        "      outputs = model(inputs)  # Forward pass\n",
        "      loss = criterion(outputs.squeeze(), targets.float())  # Calculating loss\n",
        "      loss.backward()  # Backpropagation\n",
        "      optimizer.step()\n",
        "\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "\n",
        "  with torch.no_grad(): # Testing the accuracy of the model on the test dataset per epoch\n",
        "    for test_inputs, test_targets in test_loader:\n",
        "      test_inputs, test_targets = test_inputs.to(device).float(), test_targets.to(device).long()\n",
        "      test_outputs = model(test_inputs)\n",
        "      _, predicted = torch.max(test_outputs, 1)\n",
        "      correct_predictions += (predicted == torch.argmax(test_targets, dim=1)).sum().item()\n",
        "      total_predictions += test_targets.size(0)\n",
        "\n",
        "  accuracy = (correct_predictions / total_predictions) * 100\n",
        "  print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only some the last epochs of training are showed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B__Ygbwo67BS"
      },
      "source": [
        "Testing the model (that reached 98.4% of accuracy on testing!) with a particular image of the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "U8ym2ffq8oQm",
        "outputId": "50705079-c762-4ca9-cf9d-c31556148b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\srene\\AppData\\Local\\Temp\\ipykernel_18248\\759376564.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output = model(torch.tensor(image)).to(device)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image, label = test_dataset[1]\n",
        "image = image.unsqueeze(0).to(device) # Adding one more dimension to the position 0 so that it can go through the conv2ds layers\n",
        "\n",
        "# Making the prediction without gradient descent so it's faster\n",
        "with torch.no_grad():\n",
        "    output = model(torch.tensor(image)).to(device)\n",
        "\n",
        "# Obtaining the predicted class (index with highest probability)\n",
        "predicted_class = output.argmax(dim=1).item()\n",
        "\n",
        "print(f'Predicted class: {predicted_class}')\n",
        "image = image.squeeze(0).cpu().numpy()  # Eliminates the added dimension to the batch and moves it to the cpu\n",
        "\n",
        "plt.imshow(image[0], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytdml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
